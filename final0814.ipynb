{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Class #0 = cats\n",
      "Class #1 = dogs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 41s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 08:09:45.418452 141284 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100352)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 2)            200706      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,788,418\n",
      "Trainable params: 23,735,298\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 4334s 12s/step - loss: 0.8410 - acc: 0.7443 - val_loss: 0.1681 - val_acc: 0.9420\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4336s 12s/step - loss: 0.4222 - acc: 0.8773 - val_loss: 0.1229 - val_acc: 0.9620\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 4329s 12s/step - loss: 0.3541 - acc: 0.9020 - val_loss: 0.0999 - val_acc: 0.9730\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 4319s 12s/step - loss: 0.2790 - acc: 0.9163 - val_loss: 0.0931 - val_acc: 0.9730\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4307s 11s/step - loss: 0.2829 - acc: 0.9257 - val_loss: 0.0876 - val_acc: 0.9790\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 4311s 11s/step - loss: 0.2108 - acc: 0.9373 - val_loss: 0.0859 - val_acc: 0.9760\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4314s 12s/step - loss: 0.1868 - acc: 0.9510 - val_loss: 0.0767 - val_acc: 0.9770\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 4373s 12s/step - loss: 0.1792 - acc: 0.9490 - val_loss: 0.0714 - val_acc: 0.9790\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 4312s 11s/step - loss: 0.1925 - acc: 0.9490 - val_loss: 0.0729 - val_acc: 0.9780\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 4311s 11s/step - loss: 0.1479 - acc: 0.9573 - val_loss: 0.0736 - val_acc: 0.9820\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 4335s 12s/step - loss: 0.1581 - acc: 0.9537 - val_loss: 0.0745 - val_acc: 0.9790\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 4328s 12s/step - loss: 0.1285 - acc: 0.9627 - val_loss: 0.0688 - val_acc: 0.9800\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 4384s 12s/step - loss: 0.1302 - acc: 0.9633 - val_loss: 0.0614 - val_acc: 0.9800\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 4353s 12s/step - loss: 0.1130 - acc: 0.9670 - val_loss: 0.0603 - val_acc: 0.9810\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 4342s 12s/step - loss: 0.0926 - acc: 0.9713 - val_loss: 0.0780 - val_acc: 0.9790\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 4344s 12s/step - loss: 0.0894 - acc: 0.9730 - val_loss: 0.0545 - val_acc: 0.9820\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4656s 12s/step - loss: 0.0989 - acc: 0.9707 - val_loss: 0.0618 - val_acc: 0.9830\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4359s 12s/step - loss: 0.0763 - acc: 0.9760 - val_loss: 0.1056 - val_acc: 0.9740\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 4361s 12s/step - loss: 0.0452 - acc: 0.9817 - val_loss: 0.0527 - val_acc: 0.9850\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4357s 12s/step - loss: 0.0713 - acc: 0.9780 - val_loss: 0.0753 - val_acc: 0.9770\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 資料路徑\n",
    "DATASET_PATH  = 'data'\n",
    "\n",
    "# 影像大小\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# 影像類別數\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 凍結網路層數\n",
    "FREEZE_LAYERS = 2\n",
    "\n",
    "# Epoch 數\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# 模型輸出儲存的檔案\n",
    "WEIGHTS_FINAL = 'model-resnet50-final.h5'\n",
    "\n",
    "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "# 輸出各類別的索引值\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))\n",
    "\n",
    "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
    "# 捨棄 ResNet50 頂層的 fully connected layers\n",
    "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 增加 DropOut layer\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "# 設定凍結與要進行訓練的網路層\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
    "net_final.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 輸出整個網路結構\n",
    "print(net_final.summary())\n",
    "\n",
    "# 訓練模型\n",
    "net_final.fit_generator(train_batches,\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = valid_batches,\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        epochs = NUM_EPOCHS)\n",
    "\n",
    "# 儲存訓練好的模型\n",
    "net_final.save(WEIGHTS_FINAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\test\\\\000.jpg', 'data\\\\test\\\\001.jpg', 'data\\\\test\\\\002.jpg', 'data\\\\test\\\\003.jpg', 'data\\\\test\\\\004.jpg', 'data\\\\test\\\\005.jpg', 'data\\\\test\\\\006.jpg', 'data\\\\test\\\\007.jpg', 'data\\\\test\\\\008.jpg', 'data\\\\test\\\\009.jpg', 'data\\\\test\\\\010.jpg', 'data\\\\test\\\\011.jpg', 'data\\\\test\\\\012.jpg', 'data\\\\test\\\\013.jpg', 'data\\\\test\\\\014.jpg', 'data\\\\test\\\\015.jpg', 'data\\\\test\\\\016.jpg', 'data\\\\test\\\\017.jpg', 'data\\\\test\\\\018.jpg', 'data\\\\test\\\\019.jpg', 'data\\\\test\\\\020.jpg', 'data\\\\test\\\\021.jpg', 'data\\\\test\\\\022.jpg', 'data\\\\test\\\\023.jpg', 'data\\\\test\\\\024.jpg', 'data\\\\test\\\\025.jpg', 'data\\\\test\\\\026.jpg', 'data\\\\test\\\\027.jpg', 'data\\\\test\\\\028.jpg', 'data\\\\test\\\\029.jpg', 'data\\\\test\\\\030.jpg', 'data\\\\test\\\\031.jpg', 'data\\\\test\\\\032.jpg', 'data\\\\test\\\\033.jpg', 'data\\\\test\\\\034.jpg', 'data\\\\test\\\\035.jpg', 'data\\\\test\\\\036.jpg', 'data\\\\test\\\\037.jpg', 'data\\\\test\\\\038.jpg', 'data\\\\test\\\\039.jpg', 'data\\\\test\\\\040.jpg', 'data\\\\test\\\\041.jpg', 'data\\\\test\\\\042.jpg', 'data\\\\test\\\\043.jpg', 'data\\\\test\\\\044.jpg', 'data\\\\test\\\\045.jpg', 'data\\\\test\\\\046.jpg', 'data\\\\test\\\\047.jpg', 'data\\\\test\\\\048.jpg', 'data\\\\test\\\\049.jpg', 'data\\\\test\\\\050.jpg', 'data\\\\test\\\\051.jpg', 'data\\\\test\\\\052.jpg', 'data\\\\test\\\\053.jpg', 'data\\\\test\\\\054.jpg', 'data\\\\test\\\\055.jpg', 'data\\\\test\\\\056.jpg', 'data\\\\test\\\\057.jpg', 'data\\\\test\\\\058.jpg', 'data\\\\test\\\\059.jpg', 'data\\\\test\\\\060.jpg', 'data\\\\test\\\\061.jpg', 'data\\\\test\\\\062.jpg', 'data\\\\test\\\\063.jpg', 'data\\\\test\\\\064.jpg', 'data\\\\test\\\\065.jpg', 'data\\\\test\\\\066.jpg', 'data\\\\test\\\\067.jpg', 'data\\\\test\\\\068.jpg', 'data\\\\test\\\\069.jpg', 'data\\\\test\\\\070.jpg', 'data\\\\test\\\\071.jpg', 'data\\\\test\\\\072.jpg', 'data\\\\test\\\\073.jpg', 'data\\\\test\\\\074.jpg', 'data\\\\test\\\\075.jpg', 'data\\\\test\\\\076.jpg', 'data\\\\test\\\\077.jpg', 'data\\\\test\\\\078.jpg', 'data\\\\test\\\\079.jpg', 'data\\\\test\\\\080.jpg', 'data\\\\test\\\\081.jpg', 'data\\\\test\\\\082.jpg', 'data\\\\test\\\\083.jpg', 'data\\\\test\\\\084.jpg', 'data\\\\test\\\\085.jpg', 'data\\\\test\\\\086.jpg', 'data\\\\test\\\\087.jpg', 'data\\\\test\\\\088.jpg', 'data\\\\test\\\\089.jpg', 'data\\\\test\\\\090.jpg', 'data\\\\test\\\\091.jpg', 'data\\\\test\\\\092.jpg', 'data\\\\test\\\\093.jpg', 'data\\\\test\\\\094.jpg', 'data\\\\test\\\\095.jpg', 'data\\\\test\\\\096.jpg', 'data\\\\test\\\\097.jpg', 'data\\\\test\\\\098.jpg', 'data\\\\test\\\\099.jpg', 'data\\\\test\\\\100.jpg', 'data\\\\test\\\\101.jpg', 'data\\\\test\\\\102.jpg', 'data\\\\test\\\\103.jpg', 'data\\\\test\\\\104.jpg', 'data\\\\test\\\\105.jpg', 'data\\\\test\\\\106.jpg', 'data\\\\test\\\\107.jpg', 'data\\\\test\\\\108.jpg', 'data\\\\test\\\\109.jpg', 'data\\\\test\\\\110.jpg', 'data\\\\test\\\\111.jpg', 'data\\\\test\\\\112.jpg', 'data\\\\test\\\\113.jpg', 'data\\\\test\\\\114.jpg', 'data\\\\test\\\\115.jpg', 'data\\\\test\\\\116.jpg', 'data\\\\test\\\\117.jpg', 'data\\\\test\\\\118.jpg', 'data\\\\test\\\\119.jpg', 'data\\\\test\\\\120.jpg', 'data\\\\test\\\\121.jpg', 'data\\\\test\\\\122.jpg', 'data\\\\test\\\\123.jpg', 'data\\\\test\\\\124.jpg', 'data\\\\test\\\\125.jpg', 'data\\\\test\\\\126.jpg', 'data\\\\test\\\\127.jpg', 'data\\\\test\\\\128.jpg', 'data\\\\test\\\\129.jpg', 'data\\\\test\\\\130.jpg', 'data\\\\test\\\\131.jpg', 'data\\\\test\\\\132.jpg', 'data\\\\test\\\\133.jpg', 'data\\\\test\\\\134.jpg', 'data\\\\test\\\\135.jpg', 'data\\\\test\\\\136.jpg', 'data\\\\test\\\\137.jpg', 'data\\\\test\\\\138.jpg', 'data\\\\test\\\\139.jpg', 'data\\\\test\\\\140.jpg', 'data\\\\test\\\\141.jpg', 'data\\\\test\\\\142.jpg', 'data\\\\test\\\\143.jpg', 'data\\\\test\\\\144.jpg', 'data\\\\test\\\\145.jpg', 'data\\\\test\\\\146.jpg', 'data\\\\test\\\\147.jpg', 'data\\\\test\\\\148.jpg', 'data\\\\test\\\\149.jpg', 'data\\\\test\\\\150.jpg', 'data\\\\test\\\\151.jpg', 'data\\\\test\\\\152.jpg', 'data\\\\test\\\\153.jpg', 'data\\\\test\\\\154.jpg', 'data\\\\test\\\\155.jpg', 'data\\\\test\\\\156.jpg', 'data\\\\test\\\\157.jpg', 'data\\\\test\\\\158.jpg', 'data\\\\test\\\\159.jpg', 'data\\\\test\\\\160.jpg', 'data\\\\test\\\\161.jpg', 'data\\\\test\\\\162.jpg', 'data\\\\test\\\\163.jpg', 'data\\\\test\\\\164.jpg', 'data\\\\test\\\\165.jpg', 'data\\\\test\\\\166.jpg', 'data\\\\test\\\\167.jpg', 'data\\\\test\\\\168.jpg', 'data\\\\test\\\\169.jpg', 'data\\\\test\\\\170.jpg', 'data\\\\test\\\\171.jpg', 'data\\\\test\\\\172.jpg', 'data\\\\test\\\\173.jpg', 'data\\\\test\\\\174.jpg', 'data\\\\test\\\\175.jpg', 'data\\\\test\\\\176.jpg', 'data\\\\test\\\\177.jpg', 'data\\\\test\\\\178.jpg', 'data\\\\test\\\\179.jpg', 'data\\\\test\\\\180.jpg', 'data\\\\test\\\\181.jpg', 'data\\\\test\\\\182.jpg', 'data\\\\test\\\\183.jpg', 'data\\\\test\\\\184.jpg', 'data\\\\test\\\\185.jpg', 'data\\\\test\\\\186.jpg', 'data\\\\test\\\\187.jpg', 'data\\\\test\\\\188.jpg', 'data\\\\test\\\\189.jpg', 'data\\\\test\\\\190.jpg', 'data\\\\test\\\\191.jpg', 'data\\\\test\\\\192.jpg', 'data\\\\test\\\\193.jpg', 'data\\\\test\\\\194.jpg', 'data\\\\test\\\\195.jpg', 'data\\\\test\\\\196.jpg', 'data\\\\test\\\\197.jpg', 'data\\\\test\\\\198.jpg', 'data\\\\test\\\\199.jpg', 'data\\\\test\\\\200.jpg', 'data\\\\test\\\\201.jpg', 'data\\\\test\\\\202.jpg', 'data\\\\test\\\\203.jpg', 'data\\\\test\\\\204.jpg', 'data\\\\test\\\\205.jpg', 'data\\\\test\\\\206.jpg', 'data\\\\test\\\\207.jpg', 'data\\\\test\\\\208.jpg', 'data\\\\test\\\\209.jpg', 'data\\\\test\\\\210.jpg', 'data\\\\test\\\\211.jpg', 'data\\\\test\\\\212.jpg', 'data\\\\test\\\\213.jpg', 'data\\\\test\\\\214.jpg', 'data\\\\test\\\\215.jpg', 'data\\\\test\\\\216.jpg', 'data\\\\test\\\\217.jpg', 'data\\\\test\\\\218.jpg', 'data\\\\test\\\\219.jpg', 'data\\\\test\\\\220.jpg', 'data\\\\test\\\\221.jpg', 'data\\\\test\\\\222.jpg', 'data\\\\test\\\\223.jpg', 'data\\\\test\\\\224.jpg', 'data\\\\test\\\\225.jpg', 'data\\\\test\\\\226.jpg', 'data\\\\test\\\\227.jpg', 'data\\\\test\\\\228.jpg', 'data\\\\test\\\\229.jpg', 'data\\\\test\\\\230.jpg', 'data\\\\test\\\\231.jpg', 'data\\\\test\\\\232.jpg', 'data\\\\test\\\\233.jpg', 'data\\\\test\\\\234.jpg', 'data\\\\test\\\\235.jpg', 'data\\\\test\\\\236.jpg', 'data\\\\test\\\\237.jpg', 'data\\\\test\\\\238.jpg', 'data\\\\test\\\\239.jpg', 'data\\\\test\\\\240.jpg', 'data\\\\test\\\\241.jpg', 'data\\\\test\\\\242.jpg', 'data\\\\test\\\\243.jpg', 'data\\\\test\\\\244.jpg', 'data\\\\test\\\\245.jpg', 'data\\\\test\\\\246.jpg', 'data\\\\test\\\\247.jpg', 'data\\\\test\\\\248.jpg', 'data\\\\test\\\\249.jpg', 'data\\\\test\\\\250.jpg', 'data\\\\test\\\\251.jpg', 'data\\\\test\\\\252.jpg', 'data\\\\test\\\\253.jpg', 'data\\\\test\\\\254.jpg', 'data\\\\test\\\\255.jpg', 'data\\\\test\\\\256.jpg', 'data\\\\test\\\\257.jpg', 'data\\\\test\\\\258.jpg', 'data\\\\test\\\\259.jpg', 'data\\\\test\\\\260.jpg', 'data\\\\test\\\\261.jpg', 'data\\\\test\\\\262.jpg', 'data\\\\test\\\\263.jpg', 'data\\\\test\\\\264.jpg', 'data\\\\test\\\\265.jpg', 'data\\\\test\\\\266.jpg', 'data\\\\test\\\\267.jpg', 'data\\\\test\\\\268.jpg', 'data\\\\test\\\\269.jpg', 'data\\\\test\\\\270.jpg', 'data\\\\test\\\\271.jpg', 'data\\\\test\\\\272.jpg', 'data\\\\test\\\\273.jpg', 'data\\\\test\\\\274.jpg', 'data\\\\test\\\\275.jpg', 'data\\\\test\\\\276.jpg', 'data\\\\test\\\\277.jpg', 'data\\\\test\\\\278.jpg', 'data\\\\test\\\\279.jpg', 'data\\\\test\\\\280.jpg', 'data\\\\test\\\\281.jpg', 'data\\\\test\\\\282.jpg', 'data\\\\test\\\\283.jpg', 'data\\\\test\\\\284.jpg', 'data\\\\test\\\\285.jpg', 'data\\\\test\\\\286.jpg', 'data\\\\test\\\\287.jpg', 'data\\\\test\\\\288.jpg', 'data\\\\test\\\\289.jpg', 'data\\\\test\\\\290.jpg', 'data\\\\test\\\\291.jpg', 'data\\\\test\\\\292.jpg', 'data\\\\test\\\\293.jpg', 'data\\\\test\\\\294.jpg', 'data\\\\test\\\\295.jpg', 'data\\\\test\\\\296.jpg', 'data\\\\test\\\\297.jpg', 'data\\\\test\\\\298.jpg', 'data\\\\test\\\\299.jpg', 'data\\\\test\\\\300.jpg', 'data\\\\test\\\\301.jpg', 'data\\\\test\\\\302.jpg', 'data\\\\test\\\\303.jpg', 'data\\\\test\\\\304.jpg', 'data\\\\test\\\\305.jpg', 'data\\\\test\\\\306.jpg', 'data\\\\test\\\\307.jpg', 'data\\\\test\\\\308.jpg', 'data\\\\test\\\\309.jpg', 'data\\\\test\\\\310.jpg', 'data\\\\test\\\\311.jpg', 'data\\\\test\\\\312.jpg', 'data\\\\test\\\\313.jpg', 'data\\\\test\\\\314.jpg', 'data\\\\test\\\\315.jpg', 'data\\\\test\\\\316.jpg', 'data\\\\test\\\\317.jpg', 'data\\\\test\\\\318.jpg', 'data\\\\test\\\\319.jpg', 'data\\\\test\\\\320.jpg', 'data\\\\test\\\\321.jpg', 'data\\\\test\\\\322.jpg', 'data\\\\test\\\\323.jpg', 'data\\\\test\\\\324.jpg', 'data\\\\test\\\\325.jpg', 'data\\\\test\\\\326.jpg', 'data\\\\test\\\\327.jpg', 'data\\\\test\\\\328.jpg', 'data\\\\test\\\\329.jpg', 'data\\\\test\\\\330.jpg', 'data\\\\test\\\\331.jpg', 'data\\\\test\\\\332.jpg', 'data\\\\test\\\\333.jpg', 'data\\\\test\\\\334.jpg', 'data\\\\test\\\\335.jpg', 'data\\\\test\\\\336.jpg', 'data\\\\test\\\\337.jpg', 'data\\\\test\\\\338.jpg', 'data\\\\test\\\\339.jpg', 'data\\\\test\\\\340.jpg', 'data\\\\test\\\\341.jpg', 'data\\\\test\\\\342.jpg', 'data\\\\test\\\\343.jpg', 'data\\\\test\\\\344.jpg', 'data\\\\test\\\\345.jpg', 'data\\\\test\\\\346.jpg', 'data\\\\test\\\\347.jpg', 'data\\\\test\\\\348.jpg', 'data\\\\test\\\\349.jpg', 'data\\\\test\\\\350.jpg', 'data\\\\test\\\\351.jpg', 'data\\\\test\\\\352.jpg', 'data\\\\test\\\\353.jpg', 'data\\\\test\\\\354.jpg', 'data\\\\test\\\\355.jpg', 'data\\\\test\\\\356.jpg', 'data\\\\test\\\\357.jpg', 'data\\\\test\\\\358.jpg', 'data\\\\test\\\\359.jpg', 'data\\\\test\\\\360.jpg', 'data\\\\test\\\\361.jpg', 'data\\\\test\\\\362.jpg', 'data\\\\test\\\\363.jpg', 'data\\\\test\\\\364.jpg', 'data\\\\test\\\\365.jpg', 'data\\\\test\\\\366.jpg', 'data\\\\test\\\\367.jpg', 'data\\\\test\\\\368.jpg', 'data\\\\test\\\\369.jpg', 'data\\\\test\\\\370.jpg', 'data\\\\test\\\\371.jpg', 'data\\\\test\\\\372.jpg', 'data\\\\test\\\\373.jpg', 'data\\\\test\\\\374.jpg', 'data\\\\test\\\\375.jpg', 'data\\\\test\\\\376.jpg', 'data\\\\test\\\\377.jpg', 'data\\\\test\\\\378.jpg', 'data\\\\test\\\\379.jpg', 'data\\\\test\\\\380.jpg', 'data\\\\test\\\\381.jpg', 'data\\\\test\\\\382.jpg', 'data\\\\test\\\\383.jpg', 'data\\\\test\\\\384.jpg', 'data\\\\test\\\\385.jpg', 'data\\\\test\\\\386.jpg', 'data\\\\test\\\\387.jpg', 'data\\\\test\\\\388.jpg', 'data\\\\test\\\\389.jpg', 'data\\\\test\\\\390.jpg', 'data\\\\test\\\\391.jpg', 'data\\\\test\\\\392.jpg', 'data\\\\test\\\\393.jpg', 'data\\\\test\\\\394.jpg', 'data\\\\test\\\\395.jpg', 'data\\\\test\\\\396.jpg', 'data\\\\test\\\\397.jpg', 'data\\\\test\\\\398.jpg', 'data\\\\test\\\\399.jpg']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "    1.000  cats\n",
      "001\n",
      "    0.000  cats\n",
      "002\n",
      "    1.000  cats\n",
      "003\n",
      "    0.000  cats\n",
      "004\n",
      "    1.000  cats\n",
      "005\n",
      "    1.000  cats\n",
      "006\n",
      "    0.000  cats\n",
      "007\n",
      "    1.000  cats\n",
      "008\n",
      "    1.000  cats\n",
      "009\n",
      "    1.000  cats\n",
      "010\n",
      "    0.000  cats\n",
      "011\n",
      "    1.000  cats\n",
      "012\n",
      "    0.000  cats\n",
      "013\n",
      "    1.000  cats\n",
      "014\n",
      "    1.000  cats\n",
      "015\n",
      "    0.000  cats\n",
      "016\n",
      "    0.000  cats\n",
      "017\n",
      "    1.000  cats\n",
      "018\n",
      "    0.000  cats\n",
      "019\n",
      "    1.000  cats\n",
      "020\n",
      "    1.000  cats\n",
      "021\n",
      "    1.000  cats\n",
      "022\n",
      "    1.000  cats\n",
      "023\n",
      "    1.000  cats\n",
      "024\n",
      "    1.000  cats\n",
      "025\n",
      "    0.000  cats\n",
      "026\n",
      "    0.000  cats\n",
      "027\n",
      "    0.000  cats\n",
      "028\n",
      "    0.000  cats\n",
      "029\n",
      "    0.000  cats\n",
      "030\n",
      "    0.000  cats\n",
      "031\n",
      "    0.000  cats\n",
      "032\n",
      "    0.000  cats\n",
      "033\n",
      "    1.000  cats\n",
      "034\n",
      "    1.000  cats\n",
      "035\n",
      "    0.000  cats\n",
      "036\n",
      "    1.000  cats\n",
      "037\n",
      "    1.000  cats\n",
      "038\n",
      "    0.000  cats\n",
      "039\n",
      "    1.000  cats\n",
      "040\n",
      "    0.000  cats\n",
      "041\n",
      "    0.000  cats\n",
      "042\n",
      "    1.000  cats\n",
      "043\n",
      "    1.000  cats\n",
      "044\n",
      "    1.000  cats\n",
      "045\n",
      "    0.000  cats\n",
      "046\n",
      "    0.999  cats\n",
      "047\n",
      "    1.000  cats\n",
      "048\n",
      "    0.005  cats\n",
      "049\n",
      "    1.000  cats\n",
      "050\n",
      "    1.000  cats\n",
      "051\n",
      "    1.000  cats\n",
      "052\n",
      "    0.000  cats\n",
      "053\n",
      "    1.000  cats\n",
      "054\n",
      "    0.000  cats\n",
      "055\n",
      "    0.000  cats\n",
      "056\n",
      "    0.000  cats\n",
      "057\n",
      "    1.000  cats\n",
      "058\n",
      "    1.000  cats\n",
      "059\n",
      "    1.000  cats\n",
      "060\n",
      "    0.000  cats\n",
      "061\n",
      "    1.000  cats\n",
      "062\n",
      "    1.000  cats\n",
      "063\n",
      "    0.000  cats\n",
      "064\n",
      "    1.000  cats\n",
      "065\n",
      "    1.000  cats\n",
      "066\n",
      "    0.997  cats\n",
      "067\n",
      "    1.000  cats\n",
      "068\n",
      "    0.000  cats\n",
      "069\n",
      "    1.000  cats\n",
      "070\n",
      "    0.004  cats\n",
      "071\n",
      "    0.000  cats\n",
      "072\n",
      "    1.000  cats\n",
      "073\n",
      "    1.000  cats\n",
      "074\n",
      "    1.000  cats\n",
      "075\n",
      "    0.108  cats\n",
      "076\n",
      "    1.000  cats\n",
      "077\n",
      "    0.000  cats\n",
      "078\n",
      "    1.000  cats\n",
      "079\n",
      "    0.000  cats\n",
      "080\n",
      "    0.000  cats\n",
      "081\n",
      "    0.060  cats\n",
      "082\n",
      "    1.000  cats\n",
      "083\n",
      "    0.977  cats\n",
      "084\n",
      "    0.000  cats\n",
      "085\n",
      "    0.000  cats\n",
      "086\n",
      "    0.998  cats\n",
      "087\n",
      "    1.000  cats\n",
      "088\n",
      "    1.000  cats\n",
      "089\n",
      "    0.000  cats\n",
      "090\n",
      "    1.000  cats\n",
      "091\n",
      "    0.000  cats\n",
      "092\n",
      "    0.000  cats\n",
      "093\n",
      "    0.000  cats\n",
      "094\n",
      "    1.000  cats\n",
      "095\n",
      "    0.000  cats\n",
      "096\n",
      "    1.000  cats\n",
      "097\n",
      "    1.000  cats\n",
      "098\n",
      "    0.038  cats\n",
      "099\n",
      "    1.000  cats\n",
      "100\n",
      "    0.000  cats\n",
      "101\n",
      "    0.000  cats\n",
      "102\n",
      "    0.984  cats\n",
      "103\n",
      "    0.000  cats\n",
      "104\n",
      "    1.000  cats\n",
      "105\n",
      "    0.000  cats\n",
      "106\n",
      "    0.000  cats\n",
      "107\n",
      "    1.000  cats\n",
      "108\n",
      "    0.000  cats\n",
      "109\n",
      "    0.000  cats\n",
      "110\n",
      "    0.645  cats\n",
      "111\n",
      "    0.000  cats\n",
      "112\n",
      "    1.000  cats\n",
      "113\n",
      "    0.000  cats\n",
      "114\n",
      "    0.000  cats\n",
      "115\n",
      "    0.000  cats\n",
      "116\n",
      "    0.823  cats\n",
      "117\n",
      "    0.000  cats\n",
      "118\n",
      "    0.000  cats\n",
      "119\n",
      "    1.000  cats\n",
      "120\n",
      "    1.000  cats\n",
      "121\n",
      "    0.000  cats\n",
      "122\n",
      "    1.000  cats\n",
      "123\n",
      "    1.000  cats\n",
      "124\n",
      "    1.000  cats\n",
      "125\n",
      "    0.000  cats\n",
      "126\n",
      "    0.000  cats\n",
      "127\n",
      "    0.000  cats\n",
      "128\n",
      "    0.000  cats\n",
      "129\n",
      "    1.000  cats\n",
      "130\n",
      "    0.000  cats\n",
      "131\n",
      "    0.000  cats\n",
      "132\n",
      "    1.000  cats\n",
      "133\n",
      "    0.798  cats\n",
      "134\n",
      "    0.951  cats\n",
      "135\n",
      "    0.000  cats\n",
      "136\n",
      "    1.000  cats\n",
      "137\n",
      "    1.000  cats\n",
      "138\n",
      "    0.000  cats\n",
      "139\n",
      "    0.000  cats\n",
      "140\n",
      "    0.002  cats\n",
      "141\n",
      "    1.000  cats\n",
      "142\n",
      "    1.000  cats\n",
      "143\n",
      "    1.000  cats\n",
      "144\n",
      "    1.000  cats\n",
      "145\n",
      "    0.000  cats\n",
      "146\n",
      "    0.000  cats\n",
      "147\n",
      "    1.000  cats\n",
      "148\n",
      "    0.000  cats\n",
      "149\n",
      "    0.000  cats\n",
      "150\n",
      "    0.990  cats\n",
      "151\n",
      "    1.000  cats\n",
      "152\n",
      "    0.785  cats\n",
      "153\n",
      "    0.000  cats\n",
      "154\n",
      "    0.000  cats\n",
      "155\n",
      "    0.990  cats\n",
      "156\n",
      "    0.996  cats\n",
      "157\n",
      "    0.000  cats\n",
      "158\n",
      "    0.000  cats\n",
      "159\n",
      "    1.000  cats\n",
      "160\n",
      "    0.000  cats\n",
      "161\n",
      "    0.000  cats\n",
      "162\n",
      "    0.000  cats\n",
      "163\n",
      "    0.000  cats\n",
      "164\n",
      "    0.000  cats\n",
      "165\n",
      "    1.000  cats\n",
      "166\n",
      "    1.000  cats\n",
      "167\n",
      "    1.000  cats\n",
      "168\n",
      "    0.000  cats\n",
      "169\n",
      "    1.000  cats\n",
      "170\n",
      "    0.862  cats\n",
      "171\n",
      "    1.000  cats\n",
      "172\n",
      "    0.968  cats\n",
      "173\n",
      "    0.000  cats\n",
      "174\n",
      "    0.000  cats\n",
      "175\n",
      "    0.990  cats\n",
      "176\n",
      "    0.000  cats\n",
      "177\n",
      "    0.000  cats\n",
      "178\n",
      "    1.000  cats\n",
      "179\n",
      "    0.000  cats\n",
      "180\n",
      "    1.000  cats\n",
      "181\n",
      "    1.000  cats\n",
      "182\n",
      "    0.000  cats\n",
      "183\n",
      "    0.000  cats\n",
      "184\n",
      "    0.000  cats\n",
      "185\n",
      "    1.000  cats\n",
      "186\n",
      "    1.000  cats\n",
      "187\n",
      "    0.000  cats\n",
      "188\n",
      "    0.000  cats\n",
      "189\n",
      "    1.000  cats\n",
      "190\n",
      "    0.000  cats\n",
      "191\n",
      "    0.000  cats\n",
      "192\n",
      "    0.000  cats\n",
      "193\n",
      "    1.000  cats\n",
      "194\n",
      "    0.000  cats\n",
      "195\n",
      "    0.000  cats\n",
      "196\n",
      "    0.000  cats\n",
      "197\n",
      "    1.000  cats\n",
      "198\n",
      "    1.000  cats\n",
      "199\n",
      "    0.000  cats\n",
      "200\n",
      "    0.000  cats\n",
      "201\n",
      "    0.000  cats\n",
      "202\n",
      "    0.000  cats\n",
      "203\n",
      "    0.000  cats\n",
      "204\n",
      "    0.000  cats\n",
      "205\n",
      "    0.783  cats\n",
      "206\n",
      "    1.000  cats\n",
      "207\n",
      "    0.000  cats\n",
      "208\n",
      "    0.000  cats\n",
      "209\n",
      "    1.000  cats\n",
      "210\n",
      "    0.996  cats\n",
      "211\n",
      "    0.000  cats\n",
      "212\n",
      "    0.000  cats\n",
      "213\n",
      "    0.000  cats\n",
      "214\n",
      "    0.000  cats\n",
      "215\n",
      "    0.000  cats\n",
      "216\n",
      "    0.000  cats\n",
      "217\n",
      "    1.000  cats\n",
      "218\n",
      "    0.000  cats\n",
      "219\n",
      "    1.000  cats\n",
      "220\n",
      "    0.000  cats\n",
      "221\n",
      "    0.000  cats\n",
      "222\n",
      "    0.000  cats\n",
      "223\n",
      "    1.000  cats\n",
      "224\n",
      "    1.000  cats\n",
      "225\n",
      "    0.000  cats\n",
      "226\n",
      "    1.000  cats\n",
      "227\n",
      "    0.835  cats\n",
      "228\n",
      "    1.000  cats\n",
      "229\n",
      "    0.000  cats\n",
      "230\n",
      "    0.000  cats\n",
      "231\n",
      "    1.000  cats\n",
      "232\n",
      "    1.000  cats\n",
      "233\n",
      "    0.000  cats\n",
      "234\n",
      "    0.000  cats\n",
      "235\n",
      "    1.000  cats\n",
      "236\n",
      "    0.387  cats\n",
      "237\n",
      "    0.000  cats\n",
      "238\n",
      "    0.145  cats\n",
      "239\n",
      "    0.000  cats\n",
      "240\n",
      "    0.996  cats\n",
      "241\n",
      "    0.996  cats\n",
      "242\n",
      "    0.000  cats\n",
      "243\n",
      "    0.000  cats\n",
      "244\n",
      "    1.000  cats\n",
      "245\n",
      "    1.000  cats\n",
      "246\n",
      "    1.000  cats\n",
      "247\n",
      "    0.000  cats\n",
      "248\n",
      "    0.000  cats\n",
      "249\n",
      "    0.000  cats\n",
      "250\n",
      "    0.000  cats\n",
      "251\n",
      "    0.010  cats\n",
      "252\n",
      "    1.000  cats\n",
      "253\n",
      "    0.000  cats\n",
      "254\n",
      "    0.000  cats\n",
      "255\n",
      "    0.525  cats\n",
      "256\n",
      "    1.000  cats\n",
      "257\n",
      "    1.000  cats\n",
      "258\n",
      "    1.000  cats\n",
      "259\n",
      "    1.000  cats\n",
      "260\n",
      "    1.000  cats\n",
      "261\n",
      "    1.000  cats\n",
      "262\n",
      "    1.000  cats\n",
      "263\n",
      "    0.000  cats\n",
      "264\n",
      "    0.000  cats\n",
      "265\n",
      "    0.000  cats\n",
      "266\n",
      "    0.000  cats\n",
      "267\n",
      "    0.000  cats\n",
      "268\n",
      "    1.000  cats\n",
      "269\n",
      "    0.000  cats\n",
      "270\n",
      "    1.000  cats\n",
      "271\n",
      "    0.180  cats\n",
      "272\n",
      "    0.000  cats\n",
      "273\n",
      "    0.000  cats\n",
      "274\n",
      "    1.000  cats\n",
      "275\n",
      "    0.000  cats\n",
      "276\n",
      "    0.000  cats\n",
      "277\n",
      "    0.000  cats\n",
      "278\n",
      "    0.000  cats\n",
      "279\n",
      "    0.000  cats\n",
      "280\n",
      "    1.000  cats\n",
      "281\n",
      "    0.000  cats\n",
      "282\n",
      "    0.000  cats\n",
      "283\n",
      "    0.001  cats\n",
      "284\n",
      "    0.000  cats\n",
      "285\n",
      "    1.000  cats\n",
      "286\n",
      "    1.000  cats\n",
      "287\n",
      "    1.000  cats\n",
      "288\n",
      "    1.000  cats\n",
      "289\n",
      "    0.000  cats\n",
      "290\n",
      "    1.000  cats\n",
      "291\n",
      "    1.000  cats\n",
      "292\n",
      "    0.980  cats\n",
      "293\n",
      "    1.000  cats\n",
      "294\n",
      "    1.000  cats\n",
      "295\n",
      "    1.000  cats\n",
      "296\n",
      "    1.000  cats\n",
      "297\n",
      "    1.000  cats\n",
      "298\n",
      "    1.000  cats\n",
      "299\n",
      "    0.999  cats\n",
      "300\n",
      "    1.000  cats\n",
      "301\n",
      "    0.000  cats\n",
      "302\n",
      "    0.000  cats\n",
      "303\n",
      "    0.000  cats\n",
      "304\n",
      "    0.000  cats\n",
      "305\n",
      "    0.000  cats\n",
      "306\n",
      "    0.000  cats\n",
      "307\n",
      "    0.000  cats\n",
      "308\n",
      "    1.000  cats\n",
      "309\n",
      "    1.000  cats\n",
      "310\n",
      "    0.988  cats\n",
      "311\n",
      "    0.000  cats\n",
      "312\n",
      "    0.000  cats\n",
      "313\n",
      "    0.000  cats\n",
      "314\n",
      "    0.000  cats\n",
      "315\n",
      "    0.000  cats\n",
      "316\n",
      "    0.000  cats\n",
      "317\n",
      "    1.000  cats\n",
      "318\n",
      "    1.000  cats\n",
      "319\n",
      "    0.846  cats\n",
      "320\n",
      "    1.000  cats\n",
      "321\n",
      "    1.000  cats\n",
      "322\n",
      "    0.000  cats\n",
      "323\n",
      "    0.000  cats\n",
      "324\n",
      "    0.000  cats\n",
      "325\n",
      "    0.000  cats\n",
      "326\n",
      "    1.000  cats\n",
      "327\n",
      "    1.000  cats\n",
      "328\n",
      "    1.000  cats\n",
      "329\n",
      "    1.000  cats\n",
      "330\n",
      "    0.000  cats\n",
      "331\n",
      "    0.000  cats\n",
      "332\n",
      "    1.000  cats\n",
      "333\n",
      "    0.000  cats\n",
      "334\n",
      "    0.000  cats\n",
      "335\n",
      "    1.000  cats\n",
      "336\n",
      "    0.650  cats\n",
      "337\n",
      "    1.000  cats\n",
      "338\n",
      "    0.000  cats\n",
      "339\n",
      "    0.000  cats\n",
      "340\n",
      "    0.000  cats\n",
      "341\n",
      "    1.000  cats\n",
      "342\n",
      "    0.626  cats\n",
      "343\n",
      "    0.000  cats\n",
      "344\n",
      "    0.000  cats\n",
      "345\n",
      "    0.000  cats\n",
      "346\n",
      "    0.000  cats\n",
      "347\n",
      "    0.000  cats\n",
      "348\n",
      "    1.000  cats\n",
      "349\n",
      "    1.000  cats\n",
      "350\n",
      "    0.000  cats\n",
      "351\n",
      "    1.000  cats\n",
      "352\n",
      "    0.000  cats\n",
      "353\n",
      "    1.000  cats\n",
      "354\n",
      "    0.000  cats\n",
      "355\n",
      "    1.000  cats\n",
      "356\n",
      "    1.000  cats\n",
      "357\n",
      "    1.000  cats\n",
      "358\n",
      "    1.000  cats\n",
      "359\n",
      "    1.000  cats\n",
      "360\n",
      "    0.000  cats\n",
      "361\n",
      "    1.000  cats\n",
      "362\n",
      "    0.999  cats\n",
      "363\n",
      "    0.000  cats\n",
      "364\n",
      "    1.000  cats\n",
      "365\n",
      "    1.000  cats\n",
      "366\n",
      "    0.000  cats\n",
      "367\n",
      "    0.000  cats\n",
      "368\n",
      "    1.000  cats\n",
      "369\n",
      "    0.000  cats\n",
      "370\n",
      "    1.000  cats\n",
      "371\n",
      "    0.007  cats\n",
      "372\n",
      "    1.000  cats\n",
      "373\n",
      "    0.990  cats\n",
      "374\n",
      "    0.995  cats\n",
      "375\n",
      "    0.000  cats\n",
      "376\n",
      "    0.999  cats\n",
      "377\n",
      "    1.000  cats\n",
      "378\n",
      "    0.984  cats\n",
      "379\n",
      "    0.000  cats\n",
      "380\n",
      "    0.000  cats\n",
      "381\n",
      "    0.997  cats\n",
      "382\n",
      "    0.000  cats\n",
      "383\n",
      "    1.000  cats\n",
      "384\n",
      "    1.000  cats\n",
      "385\n",
      "    0.000  cats\n",
      "386\n",
      "    0.000  cats\n",
      "387\n",
      "    0.000  cats\n",
      "388\n",
      "    0.000  cats\n",
      "389\n",
      "    0.000  cats\n",
      "390\n",
      "    1.000  cats\n",
      "391\n",
      "    0.000  cats\n",
      "392\n",
      "    0.000  cats\n",
      "393\n",
      "    1.000  cats\n",
      "394\n",
      "    0.000  cats\n",
      "395\n",
      "    0.000  cats\n",
      "396\n",
      "    0.995  cats\n",
      "397\n",
      "    1.000  cats\n",
      "398\n",
      "    1.000  cats\n",
      "399\n",
      "    1.000  cats\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>0.999992847443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>0.000000215550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002</td>\n",
       "      <td>0.999994874001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004</td>\n",
       "      <td>0.999979734421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>005</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>006</td>\n",
       "      <td>0.000000004367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>008</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>009</td>\n",
       "      <td>0.999887824059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>010</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>011</td>\n",
       "      <td>0.999999523163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>012</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>013</td>\n",
       "      <td>0.999998927116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>014</td>\n",
       "      <td>0.999997854233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>015</td>\n",
       "      <td>0.000479461742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>016</td>\n",
       "      <td>0.000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>017</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>018</td>\n",
       "      <td>0.000030840114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>019</td>\n",
       "      <td>0.999999880791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>020</td>\n",
       "      <td>0.999969720840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>021</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>022</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>023</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>024</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>025</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>026</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>027</td>\n",
       "      <td>0.000000000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>028</td>\n",
       "      <td>0.000000001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>029</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>370</td>\n",
       "      <td>0.999997496605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>0.006981591228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>372</td>\n",
       "      <td>0.999999880791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>0.989751577377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>374</td>\n",
       "      <td>0.994950890541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>0.000000586653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>0.998514711857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>0.999999880791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>0.984393894672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>0.000000037057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>0.996792018414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>0.000000000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>0.999977111816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>0.000000000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>0.000000053008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>0.000000001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>0.000000000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>0.000000035834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>0.994875133038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>1.000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Predicted\n",
       "0    000  0.999992847443\n",
       "1    001  0.000000215550\n",
       "2    002  0.999994874001\n",
       "3    003  0.000000000000\n",
       "4    004  0.999979734421\n",
       "5    005  1.000000000000\n",
       "6    006  0.000000004367\n",
       "7    007  1.000000000000\n",
       "8    008  1.000000000000\n",
       "9    009  0.999887824059\n",
       "10   010  0.000000000000\n",
       "11   011  0.999999523163\n",
       "12   012  0.000000000000\n",
       "13   013  0.999998927116\n",
       "14   014  0.999997854233\n",
       "15   015  0.000479461742\n",
       "16   016  0.000000000001\n",
       "17   017  1.000000000000\n",
       "18   018  0.000030840114\n",
       "19   019  0.999999880791\n",
       "20   020  0.999969720840\n",
       "21   021  1.000000000000\n",
       "22   022  1.000000000000\n",
       "23   023  1.000000000000\n",
       "24   024  1.000000000000\n",
       "25   025  0.000000000000\n",
       "26   026  0.000000000000\n",
       "27   027  0.000000000008\n",
       "28   028  0.000000001802\n",
       "29   029  0.000000000000\n",
       "..   ...             ...\n",
       "370  370  0.999997496605\n",
       "371  371  0.006981591228\n",
       "372  372  0.999999880791\n",
       "373  373  0.989751577377\n",
       "374  374  0.994950890541\n",
       "375  375  0.000000586653\n",
       "376  376  0.998514711857\n",
       "377  377  0.999999880791\n",
       "378  378  0.984393894672\n",
       "379  379  0.000000037057\n",
       "380  380  0.000000000000\n",
       "381  381  0.996792018414\n",
       "382  382  0.000000000028\n",
       "383  383  0.999977111816\n",
       "384  384  1.000000000000\n",
       "385  385  0.000000000000\n",
       "386  386  0.000000000008\n",
       "387  387  0.000000000000\n",
       "388  388  0.000000000000\n",
       "389  389  0.000000000000\n",
       "390  390  1.000000000000\n",
       "391  391  0.000000053008\n",
       "392  392  0.000000001126\n",
       "393  393  1.000000000000\n",
       "394  394  0.000000000451\n",
       "395  395  0.000000035834\n",
       "396  396  0.994875133038\n",
       "397  397  1.000000000000\n",
       "398  398  1.000000000000\n",
       "399  399  1.000000000000\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 從參數讀取圖檔路徑\n",
    "\n",
    "import os\n",
    "\n",
    "path = 'data\\\\test'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "print (files)\n",
    "\n",
    "# 載入訓練好的模型\n",
    "net = load_model('model-resnet50-final.h5')\n",
    "\n",
    "cls_list = ['cats', 'dogs']\n",
    "cols=['ID', 'Predicted']\n",
    "df=pd.DataFrame(columns=cols)\n",
    "# 辨識每一張圖\n",
    "for f in files:\n",
    "    img = image.load_img(f, target_size=(224, 224))\n",
    "    if img is None:\n",
    "        continue\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    pred = net.predict(x)[0]\n",
    "    top_inds = pred.argsort()[::-1][:5]\n",
    "    print(f.replace('data\\\\test\\\\','').replace('.jpg',''))\n",
    "    print('    {:.3f}  {}'.format(pred[0], cls_list[0]))\n",
    "    df=df.append({'ID':f.replace('data\\\\test\\\\','').replace('.jpg',''), 'Predicted':'{:.12f}'.format(pred[0])},ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>0.999992847443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>0.000000215550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002</td>\n",
       "      <td>0.999994874001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003</td>\n",
       "      <td>0.000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004</td>\n",
       "      <td>0.999979734421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID       Predicted\n",
       "0  000  0.999992847443\n",
       "1  001  0.000000215550\n",
       "2  002  0.999994874001\n",
       "3  003  0.000000000000\n",
       "4  004  0.999979734421"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
